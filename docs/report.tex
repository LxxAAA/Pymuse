\documentclass[journal, a4paper]{IEEEtran}

% some very useful LaTeX packages include:

%\usepackage{cite}      % Written by Donald Arseneau
                        % V1.6 and later of IEEEtran pre-defines the format
                        % of the cite.sty package \cite{} output to follow
                        % that of IEEE. Loading the cite package will
                        % result in citation numbers being automatically
                        % sorted and properly "ranged". i.e.,
                        % [1], [9], [2], [7], [5], [6]
                        % (without using cite.sty)
                        % will become:
                        % [1], [2], [5]--[7], [9] (using cite.sty)
                        % cite.sty's \cite will automatically add leading
                        % space, if needed. Use cite.sty's noadjust option
                        % (cite.sty V3.8 and later) if you want to turn this
                        % off. cite.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/cite/

\usepackage{graphicx}   % Written by David Carlisle and Sebastian Rahtz
                        % Required if you want graphics, photos, etc.
                        % graphicx.sty is already installed on most LaTeX
                        % systems. The latest version and documentation can
                        % be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/graphics/
                        % Another good source of documentation is "Using
                        % Imported Graphics in LaTeX2e" by Keith Reckdahl
                        % which can be found as esplatex.ps and epslatex.pdf
                        % at: http://www.ctan.org/tex-archive/info/

%\usepackage{psfrag}    % Written by Craig Barratt, Michael C. Grant,
                        % and David Carlisle
                        % This package allows you to substitute LaTeX
                        % commands for text in imported EPS graphic files.
                        % In this way, LaTeX symbols can be placed into
                        % graphics that have been generated by other
                        % applications. You must use latex->dvips->ps2pdf
                        % workflow (not direct pdf output from pdflatex) if
                        % you wish to use this capability because it works
                        % via some PostScript tricks. Alternatively, the
                        % graphics could be processed as separate files via
                        % psfrag and dvips, then converted to PDF for
                        % inclusion in the main file which uses pdflatex.
                        % Docs are in "The PSfrag System" by Michael C. Grant
                        % and David Carlisle. There is also some information
                        % about using psfrag in "Using Imported Graphics in
                        % LaTeX2e" by Keith Reckdahl which documents the
                        % graphicx package (see above). The psfrag package
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/psfrag/
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
%     linkcolor=blue,
%     filecolor=magenta,      
%     urlcolor=cyan,
}
 
\urlstyle{same}
%\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/

\usepackage{url}        % Written by Donald Arseneau
                        % Provides better support for handling and breaking
                        % URLs. url.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/other/misc/
                        % Read the url.sty source comments for usage information.

%\usepackage{stfloats}  % Written by Sigitas Tolusis
                        % Gives LaTeX2e the ability to do double column
                        % floats at the bottom of the page as well as the top.
                        % (e.g., "\begin{figure*}[!b]" is not normally
                        % possible in LaTeX2e). This is an invasive package
                        % which rewrites many portions of the LaTeX2e output
                        % routines. It may not work with other packages that
                        % modify the LaTeX2e output routine and/or with other
                        % versions of LaTeX. The latest version and
                        % documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/sttools/
                        % Documentation is contained in the stfloats.sty
                        % comments as well as in the presfull.pdf file.
                        % Do not use the stfloats baselinefloat ability as
                        % IEEE does not allow \baselineskip to stretch.
                        % Authors submitting work to the IEEE should note
                        % that IEEE rarely uses double column equations and
                        % that authors should try to avoid such use.
                        % Do not be tempted to use the cuted.sty or
                        % midfloat.sty package (by the same author) as IEEE
                        % does not format its papers in such ways.

\usepackage{amsmath}    % From the American Mathematical Society
                        % A popular package that provides many helpful commands
                        % for dealing with mathematics. Note that the AMSmath
                        % package sets \interdisplaylinepenalty to 10000 thus
                        % preventing page breaks from occurring within multiline
                        % equations. Use:
%\interdisplaylinepenalty=2500
                        % after loading amsmath to restore such page breaks
                        % as IEEEtran.cls normally does. amsmath.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/



% Other popular packages for formatting tables and equations include:

%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty which improves the
% LaTeX2e array and tabular environments to provide better appearances and
% additional user controls. array.sty is already installed on most systems.
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

% V1.6 of IEEEtran contains the IEEEeqnarray family of commands that can
% be used to generate multiline equations as well as matrices, tables, etc.

% Also of notable interest:
% Scott Pakin's eqparbox package for creating (automatically sized) equal
% width boxes. Available:
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/eqparbox/

% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.


% Your document starts here!
\begin{document}

% Define document title and author
	\title{Machine Learning with Music Generation}
	\author{Zhenye Na\\
    		Department of Industrial and Enterprise Systems Engineering\\
    		\url{zna2@illinois.edu}}
	\markboth{STAT578: Statistical Learning in Data Science}{}
	\maketitle

% Write abstract here
\begin{abstract}
	The goal of this project is to be able to build a generative model from scratch trying to create new musical melody. There exists some work in music generation area and they have already achieve some amazing results. More recent work is focusing on polyphonic music modeling, centered around time series probability density estimation. In this project, I tried using Generative Adversarial Network and Restricted Boltzmann Machines to create new music melody.
\end{abstract}

% Each section begins with a \section{title} command
\section{Introduction}
	% \PARstart{}{} creates a tall first letter for this first paragraph
	Music is the ultimate language for both communicating and relaxing. Many amazing composers throughout history created pieces of music. However, Is it possible for a computer to learn to create such music automatically through Machine Learning Algorithm?

	The answer is definitely true. In fact, \href{https://www.tarynsouthern.com/}{Taryn Southern} recently released her new song which is generated by AI composer, which is really fantastic. Furthermore, inspired by \href{http://www.sirajraval.com/}{Siraj Raval}'s amazing blog, I am trying to explore how to generate new music via Machine Learning Algorithms.

% Main Part
\section{Background \& Related work}
	There are several papers about both generating and classifying music. I have read some of them and below is part of them which I think is really amazing.
    
    One of the most attractive paper applies Generative Adversarial Network, written by Hao Dong et al \cite{1}, generates multi-track, both melody and harmony.

    Eck et al \cite{6}. use two different LSTM networks - one to learn chord structure and local note structure and one to learn longer term dependencies in order to try to learn a melody and retain it throughout the piece.

\section{Dataset}
	The main challenge is to select the appropriate dataset and how to represent it in order to feed to any Machine Learning algorithms. Here, I selected a midi files which contain single track, which is simplified to generate.

\subsection{Midi files}
	Midi files are structured as a series of concurrent tracks, each containing a list of meta messages and messages. Midi files are very small, but does not lose quality. It does not contain any human voice - only sound tracks. 

\subsection{Data Representation}
	In this section, several audio data representations in the context of using deep learning methods will be given. Majorities of deep learning approaches take advantage of 2-dimensional representations instead of the original 1-dimensional representation which is the (discrete) audio signal. In many cases, the two dimensions are frequency and time axes.
    
    There are several representation of sound. Based on the tutorial in Keunwoo Choi et al \cite{2} in Fig.~\ref{fig:repr}, these are the most popular ways to represent it.
 
\begin{itemize}
\item \textbf{Audio signal}: The audio signal is often called raw audio, compared to other representations that are transformations based on it.
\item \textbf{Short-Time Fourier Transform}: STFT provides a time-frequency representation with linearly-spaced center frequencies.
\item \textbf{Mel-spectrogram}: Mel-spectrogram is a 2D representation that is optimized for human auditory perception
\item \textbf{Constant-Q Transform (CQT)}: CQT provides a 2D representation with logarithmic-scale center frequencies.
\end{itemize}

	\begin{figure}[!hbt]
		% Center the figure.
		\begin{center}
		% Include the eps file, scale it such that it's width equals the column width. You can also put width=8cm for example...
		\includegraphics[width=\columnwidth]{1709.jpg}
		% Create a subtitle for the figure.
		\caption{Audio content representations. On the top, a digital audio signal is illustrated with its samples and its continuous waveform part. STFT, Mel-spectrogram, CQT, and a chroma-gram of a music signal are also plotted . Please note the different scales of frequency axes of STFT, Mel-spectrogram,
and CQT.}
		% Define the label of the figure. It's good to use 'fig:title', so you know that the label belongs to a figure.
		\label{fig:repr}
		\end{center}
	\end{figure}	


\subsection{Data Preprocessing}
	In order to feed MIDI files to Machine Learning algorithms, I manipulated MIDI files to a matrix format which is the most common data format. As in the Fig.~\ref{fig:midi}, the y-axis is note-range and x-axis is the time steps (or duration). So I used $1$ to represent the key has been pressed and $0$ to represent not in a big matrix. Also, if we observe a little bit more, we will find there exists conditional probability here. The next keys in the next time-step are conditioned on the current time-step. I merely wrapped up the data manipulation function by \href{https://github.com/dshieble/Music_RNN_RBM/blob/master/midi_manipulation.py}{Dan Shiebler} and make it suitable in my project.

	\begin{figure}[!hbt]
		% Center the figure.
		\begin{center}
		% Include the eps file, scale it such that it's width equals the column width. You can also put width=8cm for example...
		\includegraphics[width=\columnwidth]{midi_note.png}
		% Create a subtitle for the figure.
		\caption{Matrix representation of MIDI files}
		% Define the label of the figure. It's good to use 'fig:title', so you know that the label belongs to a figure.
		\label{fig:midi}
		\end{center}
	\end{figure}	

\section{Approach}
	In this section, I explored using two different approaches. One is successful and another failed. I will give some reasons why it does not work later.

\subsection{Generative Models}
Generative Models specify a probability distribution over a dataset of input vectors. For an unsupervised task, we form a model for $P(x)$, where $x$ is an input vector. For a supervised task, we form a model for $P(x|y)$, where $y$ is the label for $x$. Like discriminative models, most generative models can be used for classification tasks. To perform classification with a generative model, we leverage the fact that if we know $P(X|Y)$ and $P(Y)$, we can use Bayes rule to estimate $P(Y|X)$.

\subsection{Generative Adversarial Network}
	The first approach is to apply GAN to midi files. The goal for this project is to generate new music. So any generative models will be appropriate for this task. However, the theory behind is a little bit different. For the generator of GAN, I use two stacked LSTM and dropout layer after each LSTM layer. Because the attribute of music is sequential, the best model for sequential data is RNN. However, basic RNN is suffering from Vanishing gradient point problems. I selected LSTM instead. At the end, I use fully-connected layer for the output layer. For discriminator, I applied two Convolution layers with LeakyReLU as activation function .

    The loss function I used in cross-entropy. It is obvious that the generator ($G$) try its best to fool the discriminator ($D$), so that the loss function of $G$ is to optimize (minimize) the distance of generated songs with label $1$, which stands for real song. Meanwhile, $D$ is trying its best to distinguish the two different categories.

    The optimizer I used is RMSProp and Adam. I used Tensorflow as the Deep Learning library.\\

\begin{enumerate}
\item Dense layers\\
A dense layer is a basic module of DNNs. Dense layers have many other names - dense layer (because the connection is dense), fully-connected layers (because inputs and outputs are fully-connected), affine transform (because there is $Wx+b$), MLP (multi-layer perceptron which is a conventional name of a neural network), and confusingly and unlike in this paper, DNNs (deep neural networks, but to denote deep neural networks only with dense layers). A dense layer is formulated as follows.
$$y = f(\textbf{W} \cdot x + b)$$

	\begin{figure}[!hbt]
		% Center the figure.
		\begin{center}
		% Include the eps file, scale it such that it's width equals the column width. You can also put width=8cm for example...
		\includegraphics[scale=0.5]{dense.png}
		% Create a subtitle for the figure.
		\caption{An illustration of a dense layer that has a 4D input and 3D output.}
		% Define the label of the figure. It's good to use 'fig:title', so you know that the label belongs to a figure.
		\label{fig:conv}
		\end{center}
	\end{figure}

\item Recurrent layers\\
A recurrent layer incorporates a recurrent connection and is formulated as follows

$$y_t = f_{out}(Vh_t)$$
$$h_t = f_h(\textbf{U}x_t +\textbf{W}h_{t-1})$$

	\begin{figure}[!hbt]
		% Center the figure.
		\begin{center}
		% Include the eps file, scale it such that it's width equals the column width. You can also put width=8cm for example...
		\includegraphics[width=\columnwidth]{act.png}
		% Create a subtitle for the figure.
		\caption{Four popular activation functions - a logistic, hyper-tangential, Rectified Linear Unit (ReLU), and leaky ReLU.}
		% Define the label of the figure. It's good to use 'fig:title', so you know that the label belongs to a figure.
		\label{fig:rnn}
		\end{center}
	\end{figure}

where $f_h$ is usually tanh or ReLU, $f_{out}$ can be softmax/sigmoid/etc., ht: hidden vector of the network that stores the information at time t and \textbf{U}, \textbf{V}, \textbf{W} are matrices which are trainable weights of the recurrent layer. To distinguish the RNN with this formula from other variants of RNNs, it is often specied as vanilla RNN.

	\begin{figure}[!hbt]
		% Center the figure.
		\begin{center}
		% Include the eps file, scale it such that it's width equals the column width. You can also put width=8cm for example...
		\includegraphics[scale=0.5]{rnn.png}
		% Create a subtitle for the figure.
		\caption{Unfolded RNN with 3 time-steps}
		% Define the label of the figure. It's good to use 'fig:title', so you know that the label belongs to a figure.
		\label{fig:rnn}
		\end{center}
	\end{figure}


\end{enumerate}


\subsection{Restricted Boltzmann Machine}
	RBM is a neural network with 2 layers, the visible layer and the hidden layer. Each visible node is connected to each hidden node (and vice versa), but there are no visible-visible or hidden-hidden connections (the RBM is a complete bipartite graph). Since there are only 2 layers, we can fully describe a trained RBM with 3 parameters:
\begin{itemize}
\item The weight matrix $W$: size $n_{visible} \times n_{hidden}$. $W_{ij}$ is the weight of the connection between visible node $i$ and hidden node $j$.
\item The bias vector $bv$: vector with $n_{visible}$ elements. Element $i$ is the bias for the $i_{th}$ visible node.
\item The bias vector $bh$: vector with $n_{hidden}$ elements. Element $j$ is the bias for the $j_{th}$ hidden node.
\end{itemize}

\subsection{Gibbs Sampling}
	Gibbs sampling is a Markov Chain Monte Carlo (MCMC) algorithm for obtaining a sequence of observations which are approximated from a specified multivariate probability distribution, when direct sampling is difficult. This sequence can be used to approximate the joint distribution (e.g., to generate a histogram of the distribution); to approximate the marginal distribution of one of the variables, or some subset of the variables (for example, the unknown parameters or latent variables); or to compute an integral (such as the expected value of one of the variables). 
    
    Typically, some of the variables corresponding to observations whose values are known, and hence do not need to be sampled. It basically applies conditional probability again and again. So it is a good choice to use for sampling hidden state for this case.

\section{Experiment}
\subsection{Generative Adversarial Network}
	The result given by GAN is not so good. 10 classical music has been divided into same length of music pieces and training in 200 epochs. The generated music is very noisy. I think there are several reasons this model does not work in my case:
\begin{itemize}
\item \textbf{Loss function}: The loss function I chose may be not appropriate for this problem.
\item \textbf{Network Architecture}: architecture of Discriminator ($D$) used Convolution layers which is not the best for this problem for classifying.
\item \textbf{Sampling method}: Uniform distribution which did not contain conditional probability.
\end{itemize}

\subsection{Restricted Boltzmann Machine}
In this model, I fixed sampling method via sing Gibbs Sampling which takes conditional probability into account. At this time, RBM catch all the feature point and generate some qualified music. However, based on the time limits and Computer computational resources. I only train on 100 songs and the result is over-fitting. It can be solved via training on the

\section{Conclusion \& Future work}

This project is based on my recent crush on Garage-band for music composing and the interest in deep learning generated art. Given the recent enthusiasm in Machine Learning inspired art, I hope to continue this work by
fixing the GAN model and try other alternative generative model.

Furthermore, I will try to apply more reasonable models like VAE to it. Furthermore, Magenta (Tensorflow-backend for art) will be another good library for exploring.

% Now we need a bibliography:
\begin{thebibliography}{5}

	%Each item starts with a \bibitem{reference} command and the details thereafter.
	\bibitem{1} % Transaction paper
	Hao.~Dong, Wen.~Hsiao, L.~Yang, Y.~Yang. MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment. {\em arXiv:1709.06298}

	\bibitem{2} % Conference paper
	K.~Choi, G.~Fazekas, and K.~Cho. A Tutorial on Deep Learning for Music Information.

	\bibitem{3} % Book
	I. J.~Goodfellow, J.~Abadie, M.~Mirza, B.~Xu, D.~Farley, S.~Ozair, A.~Courville, Y.~Bengio. Generative Adversarial Networks. {\em arXiv:1406.2661}

	\bibitem{6}
    D.~Eck, J.~Schmidhuber. A first look at music composition using lstm recurrent neural networks. {\em Technical Report} No. IDSIA-07-02, 2002.


\end{thebibliography}

% Your document ends here!
\end{document}